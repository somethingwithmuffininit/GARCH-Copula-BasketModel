{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install yfinance numpy statsmodels pandas matplotlib arch pycop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1992-11-20 00:00:00+01:00    NaN\n",
      "1992-11-23 00:00:00+01:00    NaN\n",
      "1992-11-24 00:00:00+01:00    NaN\n",
      "1992-11-25 00:00:00+01:00    NaN\n",
      "1992-11-26 00:00:00+01:00    NaN\n",
      "                            ... \n",
      "2024-11-18 00:00:00+01:00    0.0\n",
      "2024-11-19 00:00:00+01:00    0.0\n",
      "2024-11-20 00:00:00+01:00    0.0\n",
      "2024-11-21 00:00:00+01:00    0.0\n",
      "2024-11-22 00:00:00+01:00    0.0\n",
      "Name: Close, Length: 8111, dtype: float64\n",
      "                          Date       Close\n",
      "0    1992-11-20 00:00:00+01:00   15.478400\n",
      "1    1992-11-23 00:00:00+01:00   15.236200\n",
      "2    1992-11-24 00:00:00+01:00   15.266801\n",
      "3    1992-11-25 00:00:00+01:00   15.134200\n",
      "4    1992-11-26 00:00:00+01:00   15.230200\n",
      "...                        ...         ...\n",
      "8106 2024-11-18 00:00:00+01:00  191.891895\n",
      "8107 2024-11-19 00:00:00+01:00  190.603105\n",
      "8108 2024-11-20 00:00:00+01:00  190.047793\n",
      "8109 2024-11-21 00:00:00+01:00  191.461699\n",
      "8110 2024-11-22 00:00:00+01:00  193.225898\n",
      "\n",
      "[8111 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamm\\AppData\\Local\\Temp\\ipykernel_8404\\378253153.py:34: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
      "  close_data['Close'] = close_data.resample('Q').last()\n",
      "C:\\Users\\liamm\\AppData\\Local\\Temp\\ipykernel_8404\\378253153.py:37: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  close_data = np.log(close_data['Close'].pct_change()+1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Series.rename() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m close_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(close_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpct_change()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Rename the columns\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m close_data \u001b[38;5;241m=\u001b[39m \u001b[43mclose_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuarterly Log Return \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Merge with the previously merged data\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merged_data\u001b[38;5;241m.\u001b[39mempty:\n",
      "\u001b[1;31mTypeError\u001b[0m: Series.rename() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of ticker symbols for each index\n",
    "tickers = [\"^GDAXI\", \"^AEX\", \"^N225\", \"^GSPC\", \"^GSPTSE\"]  # DAX, AEX, Nikkei 225, S&P 500, TSX\n",
    "\n",
    "# Initialize a DataFrame to store merged data\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Loop over each ticker symbol to fetch the data\n",
    "for ticker in tickers:\n",
    "    \n",
    "    \n",
    "    # Retrieve the historical data starting from November 20, 1992, rescaled by a factor of 0.01\n",
    "    index = yf.Ticker(ticker)\n",
    "    index_data = index.history(start=\"1992-11-20\") * 0.01\n",
    "    \n",
    "    print(close_data)\n",
    "\n",
    "    # Extract only the Date and Close columns, reset the index\n",
    "    close_data = index_data[['Close']].reset_index()\n",
    "    \n",
    "    \n",
    "    # Convert the Date column to Datetime\n",
    "    close_data['Date'] = pd.to_datetime(close_data['Date'])\n",
    "\n",
    "    print(close_data)\n",
    "\n",
    "    #Set Date as index\n",
    "    close_data.set_index('Date', inplace=True)\n",
    "\n",
    "    #Sample Data on a Quarterly Basis\n",
    "    close_data['Close'] = close_data.resample('Q').last()\n",
    "\n",
    "    #Compute Log Returns\n",
    "    close_data = np.log(close_data['Close'].pct_change()+1)\n",
    "\n",
    "\n",
    "    # Rename the columns\n",
    "    close_data = close_data.rename(columns={'Quarterly Log Return ': ticker})\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Merge with the previously merged data\n",
    "    if merged_data.empty:\n",
    "        merged_data = close_data\n",
    "    else:\n",
    "        merged_data = pd.merge(merged_data, close_data, on='Date', how='outer')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'^GDAXI'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Programming\\Risk-Management-Project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '^GDAXI'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m     nu \u001b[38;5;241m=\u001b[39m fitted\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residuals, nu\n\u001b[1;32m---> 13\u001b[0m marginal_results \u001b[38;5;241m=\u001b[39m [fit_garch(\u001b[43mquarterly_log_returns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tickers]\n\u001b[0;32m     14\u001b[0m residuals_list, nu_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mmarginal_results)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(nu_list)\n",
      "File \u001b[1;32mc:\\Programming\\Risk-Management-Project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Programming\\Risk-Management-Project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '^GDAXI'"
     ]
    }
   ],
   "source": [
    "from arch import arch_model\n",
    "from scipy.stats import t\n",
    "\n",
    "#Fit Student's t-GARCH\n",
    "def fit_garch(ts):\n",
    "    model = arch_model(ts, vol=\"Garch\", p=1, q=1, dist=\"t\")\n",
    "    fitted = model.fit(disp=\"off\")\n",
    "    residuals = ts - fitted.conditional_volatility  # Approximation for simplicity\n",
    "    nu = fitted.params[\"nu\"]\n",
    "    return residuals, nu\n",
    "\n",
    "\n",
    "marginal_results = [fit_garch(merged_data_filled[i]) for i in tickers]\n",
    "residuals_list, nu_list = zip(*marginal_results)\n",
    "\n",
    "\n",
    "print(nu_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "\n",
    "#Seed\n",
    "np.random.RandomState = 23456\n",
    "\n",
    "#Number Monte Carlo Simulations\n",
    "n = 1000\n",
    "\n",
    "simulated_data = []\n",
    "\n",
    "for i in tickers:\n",
    "    simulated_data.append(multivariate_t.rvs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Transform the data to uniform margins using ECDF (Empirical CDF)\n",
    "uniform_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Use empirical CDF for each column (ticker) in the merged data\n",
    "for ticker in tickers:\n",
    "    uniform_data[ticker] = merged_data_filled[ticker].rank() / len(merged_data_filled[ticker])\n",
    "\n",
    "# Step 2: Fit a copula (using Gaussian copula as an example)\n",
    "copula = StudentTCopula()\n",
    "\n",
    "# Step 3: Fit the copula to the uniform-transformed data\n",
    "copula.fit(uniform_data)\n",
    "\n",
    "# Step 4: Simulate synthetic data from the fitted copula (optional)\n",
    "simulated_data = copula.sample(len(merged_data_filled))\n",
    "\n",
    "# Convert the uniform data back to the original scale (inverse of the transformation)\n",
    "simulated_data_original_scale = pd.DataFrame()\n",
    "\n",
    "for idx, ticker in enumerate(tickers):\n",
    "    # Inverse transform (since we used ECDF, we can approximate the inverse by using the quantiles)\n",
    "    simulated_data_original_scale[ticker] = np.percentile(merged_data_filled[ticker], simulated_data[:, idx] * 100)\n",
    "\n",
    "# View the simulated data\n",
    "print(simulated_data_original_scale.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycop\n",
      "  Downloading pycop-0.0.13-py3-none-any.whl.metadata (11 kB)\n",
      "Downloading pycop-0.0.13-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: pycop\n",
      "Successfully installed pycop-0.0.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pycop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
