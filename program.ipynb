{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install yfinance numpy statsmodels pandas matplotlib arch openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from arch import arch_model\n",
    "from scipy.stats import t\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Data\n",
    "This cell imports index data from Yahoo Finance, using the yFinance library. Optionally, we can also make a backup of the data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List of ticker symbols for each index\n",
    "tickers = [\"^GDAXI\", \"^AEX\", \"^N225\", \"^GSPC\", \"^GSPTSE\"]  # DAX, AEX, Nikkei 225, S&P 500, TSX\n",
    "index_datasets = {}\n",
    "\n",
    "#Set to True to overwrite backup of data\n",
    "#I used this to keep a backup, incase access to data was lost during the development of this program\n",
    "OVERWRITE_DATA = False\n",
    "\n",
    "\n",
    "# Loop over each ticker symbol to fetch the data\n",
    "for ticker in tickers:\n",
    "    # Retrieve the historical data starting from November 20, 1992\n",
    "    index = yf.Ticker(ticker)\n",
    "    #Save to dictionary\n",
    "    index_datasets[ticker] = index.history(start=\"1992-11-20\")\n",
    "    # Convert the Date column to Datetime\n",
    "    (index_datasets[ticker]).index = pd.to_datetime((index_datasets[ticker]).index.normalize().tz_localize(None))\n",
    "    \n",
    "    #Optional: Write data to disk\n",
    "    if OVERWRITE_DATA: index_datasets[ticker].to_excel(\".\\\\Data Backup\\\\\"+ticker+'.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute log-returns\n",
    "\n",
    "We merge all of the data stored in the index_datasets dictionary into one Pandas dataframe. We sample the data on a quarterly basis, using a forward fill to account for any missing dates. The forward fill is required to account for different exchanges having different holidays. We then compute the quarterly log-returns for each index. We then drop all data apart from the date and quarterly log-returns from our dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store merged data\n",
    "merged_data = pd.DataFrame()\n",
    "k=0\n",
    "# Loop over each ticker symbol to fetch the data\n",
    "for ticker in tickers:\n",
    "    \n",
    "    index_data = index_datasets[ticker]\n",
    "\n",
    "    # Extract only the Date and Close columns, reset the index\n",
    "    close_data = (index_data[['Close']]).copy()\n",
    "\n",
    "    close_data.rename(columns={'Close': ticker},inplace=True)\n",
    "\n",
    "    \n",
    "    # Merge with the previously merged data\n",
    "    if merged_data.empty:\n",
    "        merged_data = close_data\n",
    "    else:\n",
    "        merged_data = pd.merge(merged_data, close_data, on='Date')\n",
    "\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    #Forward fill missing data\n",
    "    merged_data[ticker] = merged_data[ticker].ffill()\n",
    "\n",
    "\n",
    "#Resample at end of each quarter\n",
    "merged_data = merged_data.resample(\"QE\").last()\n",
    "\n",
    "#Compute Log Returns\n",
    "merged_data[:] = np.log(1+merged_data.pct_change())\n",
    "\n",
    "#Alternatively, can use simple returns\n",
    "#merged_data[:] = merged_data.pct_change()\n",
    "\n",
    "merged_data.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit Models\n",
    "Here, we first fit a Students-t GARCH model to the log-return data for each index, using the arch library.\n",
    "\n",
    "\n",
    "Note: We are actually fitting the GARCH model to 100 times the log-return data, as recommended by the library documentation. This is done to improve numerical stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Fit GARCH model using a custom distribution for the residuals\n",
    "#We will use dist = normal, t and skewt\n",
    "def fit_garch(ts, dist):\n",
    "    model = arch_model(ts, vol=\"Garch\", p=1, q=1, dist=dist, rescale=False)\n",
    "    return model.fit(disp=\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters for each model:\n",
      "\n",
      "\n",
      "Model: normal\n",
      "             ^GDAXI       ^AEX      ^N225     ^GSPC    ^GSPTSE\n",
      "mu         2.257518   2.223311   0.667560  2.191185   1.477161\n",
      "omega     34.112618  27.576664  54.024425  8.486110  15.098824\n",
      "alpha[1]   0.127333   0.306336   0.000000  0.311806   0.154551\n",
      "beta[1]    0.621484   0.453414   0.501558  0.607063   0.623137\n",
      "\n",
      "Model: t\n",
      "             ^GDAXI       ^AEX       ^N225     ^GSPC    ^GSPTSE\n",
      "mu         3.705828   3.071491    0.679163  3.082266   2.968058\n",
      "omega     45.646289  42.323276   60.924347  8.280055  56.659993\n",
      "alpha[1]   0.344502   0.408484    0.000000  0.364713   0.321408\n",
      "beta[1]    0.498170   0.383051    0.437980  0.635287   0.103756\n",
      "nu         3.067927   3.168461  386.386343  3.468832   2.961484\n",
      "\n",
      "Model: skewt\n",
      "             ^GDAXI       ^AEX       ^N225     ^GSPC    ^GSPTSE\n",
      "mu         2.133558   1.749277    0.609632  1.944797   1.507342\n",
      "omega     42.419061  36.993166   56.957267  8.011723  15.547197\n",
      "alpha[1]   0.284317   0.346959    0.017817  0.297369   0.221868\n",
      "beta[1]    0.519067   0.398089    0.453807  0.658245   0.587467\n",
      "eta        3.513520   3.703056  299.941863  4.419381   4.244029\n",
      "lambda    -0.365759  -0.334900   -0.314927 -0.469189  -0.485162\n",
      "Emperical moments for each index:\n",
      "\n",
      "\n",
      "Model: skewt\n",
      "             ^GDAXI       ^AEX       ^N225     ^GSPC    ^GSPTSE\n",
      "mu         2.133558   1.749277    0.609632  1.944797   1.507342\n",
      "omega     42.419061  36.993166   56.957267  8.011723  15.547197\n",
      "alpha[1]   0.284317   0.346959    0.017817  0.297369   0.221868\n",
      "beta[1]    0.519067   0.398089    0.453807  0.658245   0.587467\n",
      "eta        3.513520   3.703056  299.941863  4.419381   4.244029\n",
      "lambda    -0.365759  -0.334900   -0.314927 -0.469189  -0.485162\n"
     ]
    }
   ],
   "source": [
    "u_dict = {}\n",
    "residuals_dict = {}\n",
    "\n",
    "fitted_models = {}\n",
    "models = (\"normal\",\"t\",\"skewt\")\n",
    "\n",
    "norm_df,t_df,skewt_df = pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "\n",
    "#Fit each GARCH model for each index, store results in fitted_models dictionary\n",
    "for model in models:\n",
    "    for ticker in tickers:\n",
    "        fitted_models[(ticker,model)] = fit_garch(merged_data[ticker]*100,model) #as suggested by the documentation, we scale our data to improve numerical stability\n",
    "        #print(ticker, model)\n",
    "        #print(fitted_models[(ticker,model)].params)\n",
    "\n",
    "#Creates a dataframe with the fitted parameters from each model, and prints results\n",
    "print(\"Fitted parameters for each model:\\n\")\n",
    "for model in models:\n",
    "    df = pd.DataFrame(columns=tickers)\n",
    "    for ticker in tickers:\n",
    "        df[ticker] = fitted_models[(ticker,model)].params\n",
    "    print(\"\\nModel: \"+model)\n",
    "    print(round(df,10))\n",
    "\n",
    "#Creates a dataframe for the first four emperical moments, and prints results\n",
    "print(\"Emperical moments for each index:\\n\")\n",
    "df = pd.DataFrame(columns=tickers)\n",
    "for ticker in tickers:\n",
    "    df[ticker] = fitted_models[(ticker,model)].params\n",
    "print(\"\\nModel: \"+model)\n",
    "print(round(df,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we scaled our log-returns by a factor of $100$ before fitting each model. Hence, our mean returns (mu) above are scaled by a factor of $100$, while our baseline variances (omega) are scaled by a factor of $100^2$\n",
    "\n",
    "We note that, in each model, the Nikkei 225 has a fitted alpha value of approximately 0, suggesting a lack of volatility clustering. Additionally, we note that the Nikkei 225 log-returns distribution demonstrates thin tails, as demonstrated by the high degrees of freedom in both the classical and skewed Student's-t GARCH models.\n",
    "\n",
    "The other indices display much fatter tails, with fitted degrees of freedom ranging between 2.98 - 3.47,  and 3.51 - 4.42 for the classical and skewed Student's-t GARCH models, respectively.\n",
    "\n",
    "We observe that each index's returns are negatively skewed, as evident by the lambda parameter in the skewed Student's-t GARCH models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot ACF of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of columns must be a positive integer, not 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         axes[i]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACF of \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m ticker \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m GARCH Residuals\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Plot Results    \u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mplot_residual_acfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresiduals_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m, in \u001b[0;36mplot_residual_acfs\u001b[1;34m(residuals_dict)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_residual_acfs\u001b[39m(residuals_dict):\n\u001b[0;32m      3\u001b[0m     n_residuals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(residuals_dict)\n\u001b[1;32m----> 4\u001b[0m     fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_residuals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_residuals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_residuals):\n\u001b[0;32m      7\u001b[0m         ticker \u001b[38;5;241m=\u001b[39m tickers[i]\n",
      "File \u001b[1;32mc:\\Programming\\Risk-Management-Project\\.venv\\Lib\\site-packages\\matplotlib\\pyplot.py:1760\u001b[0m, in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;124;03mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[0;32m   1617\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \n\u001b[0;32m   1758\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m fig \u001b[38;5;241m=\u001b[39m figure(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfig_kw)\n\u001b[1;32m-> 1760\u001b[0m axs \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubplot_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[1;32mc:\\Programming\\Risk-Management-Project\\.venv\\Lib\\site-packages\\matplotlib\\figure.py:860\u001b[0m, in \u001b[0;36mFigureBase.subplots\u001b[1;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_ratios\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must not be defined both as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    857\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter and as key in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridspec_kw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    858\u001b[0m     gridspec_kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_ratios\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m width_ratios\n\u001b[1;32m--> 860\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_gridspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m axs \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39msubplots(sharex\u001b[38;5;241m=\u001b[39msharex, sharey\u001b[38;5;241m=\u001b[39msharey, squeeze\u001b[38;5;241m=\u001b[39msqueeze,\n\u001b[0;32m    862\u001b[0m                   subplot_kw\u001b[38;5;241m=\u001b[39msubplot_kw)\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m axs\n",
      "File \u001b[1;32mc:\\Programming\\Risk-Management-Project\\.venv\\Lib\\site-packages\\matplotlib\\figure.py:1538\u001b[0m, in \u001b[0;36mFigureBase.add_gridspec\u001b[1;34m(self, nrows, ncols, **kwargs)\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;124;03mLow-level API for creating a `.GridSpec` that has this figure as a parent.\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# pop in case user has added this...\u001b[39;00m\n\u001b[1;32m-> 1538\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[43mGridSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gs\n",
      "File \u001b[1;32mc:\\Programming\\Risk-Management-Project\\.venv\\Lib\\site-packages\\matplotlib\\gridspec.py:363\u001b[0m, in \u001b[0;36mGridSpec.__init__\u001b[1;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhspace \u001b[38;5;241m=\u001b[39m hspace\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure \u001b[38;5;241m=\u001b[39m figure\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Risk-Management-Project\\.venv\\Lib\\site-packages\\matplotlib\\gridspec.py:51\u001b[0m, in \u001b[0;36mGridSpecBase.__init__\u001b[1;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnrows\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ncols, Integral) \u001b[38;5;129;01mor\u001b[39;00m ncols \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of columns must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mncols\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nrows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ncols \u001b[38;5;241m=\u001b[39m nrows, ncols\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_height_ratios(height_ratios)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of columns must be a positive integer, not 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 0x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This plots the ACF of the residuals of each GARCH, and displays them side by side for comparision\n",
    "def plot_residual_acfs(residuals_dict):\n",
    "    n_residuals = len(residuals_dict)\n",
    "    fig, axes = plt.subplots(1, n_residuals, figsize=(5 * n_residuals, 5))\n",
    "\n",
    "    for i in range(n_residuals):\n",
    "        ticker = tickers[i]\n",
    "        plot_acf(residuals_dict[ticker], lags=50, ax=axes[i])\n",
    "        axes[i].set_title('ACF of ' + ticker + ' GARCH Residuals')\n",
    "\n",
    "#Plot Results    \n",
    "plot_residual_acfs(residuals_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Spearman's Variance-Covariance Matrix\n",
    "Using the residuals from our Student's t GARCH model, we calculate the spearman correlation of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tickers:\n\u001b[0;32m      9\u001b[0m     std_devs\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mstd(residuals_dict[i]))\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mplot\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate the variance-covariance matrix\u001b[39;00m\n\u001b[0;32m     13\u001b[0m cov_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64(spearman_corr) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(std_devs, std_devs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "spearman_corr = spearmanr(list(residuals_dict.values()),axis=1)\n",
    "\n",
    "# Calculate the standard deviations of the residuals\n",
    "std_devs = []\n",
    "for i in tickers:\n",
    "    std_devs.append(np.std(residuals_dict[i]))\n",
    "    plot\n",
    "\n",
    "# Calculate the variance-covariance matrix\n",
    "cov_matrix = np.float64(spearman_corr) * np.outer(std_devs, std_devs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cov must be 2 dimensional and square",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[204], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Number Monte Carlo Simulations\u001b[39;00m\n\u001b[0;32m      5\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m----> 7\u001b[0m simulated_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcov_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mnumpy\\\\random\\\\mtrand.pyx:4233\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cov must be 2 dimensional and square"
     ]
    }
   ],
   "source": [
    "\n",
    "#Seed\n",
    "np.random.seed(42) \n",
    "\n",
    "#Number Monte Carlo Simulations\n",
    "n = 1000\n",
    "\n",
    "simulated_data = np.random.multivariate_normal(np.zeros(len(tickers)),cov_matrix,n)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Transform the data to uniform margins using ECDF (Empirical CDF)\n",
    "uniform_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Use empirical CDF for each column (ticker) in the merged data\n",
    "for ticker in tickers:\n",
    "    uniform_data[ticker] = merged_data_filled[ticker].rank() / len(merged_data_filled[ticker])\n",
    "\n",
    "# Step 2: Fit a copula (using Gaussian copula as an example)\n",
    "copula = StudentTCopula()\n",
    "\n",
    "# Step 3: Fit the copula to the uniform-transformed data\n",
    "copula.fit(uniform_data)\n",
    "\n",
    "# Step 4: Simulate synthetic data from the fitted copula (optional)\n",
    "simulated_data = copula.sample(len(merged_data_filled))\n",
    "\n",
    "# Convert the uniform data back to the original scale (inverse of the transformation)\n",
    "simulated_data_original_scale = pd.DataFrame()\n",
    "\n",
    "for idx, ticker in enumerate(tickers):\n",
    "    # Inverse transform (since we used ECDF, we can approximate the inverse by using the quantiles)\n",
    "    simulated_data_original_scale[ticker] = np.percentile(merged_data_filled[ticker], simulated_data[:, idx] * 100)\n",
    "\n",
    "# View the simulated data\n",
    "print(simulated_data_original_scale.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycop\n",
      "  Downloading pycop-0.0.13-py3-none-any.whl.metadata (11 kB)\n",
      "Downloading pycop-0.0.13-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: pycop\n",
      "Successfully installed pycop-0.0.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
